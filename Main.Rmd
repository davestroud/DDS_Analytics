---
title: "DDS_Analytics"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(rsample)
library(yardstick)
library(corrr)
library(readxl)
library(tidyverse)
library(glmnet)
library(rpart)
library(rpart.plot)
library(randomForest)
```


```{r}
# Load raw data
raw_DDSA <- read_excel("CaseStudy2-data.xlsx")

# Change characters to factors for more meaningfull analysis
DDSA <- raw_DDSA%>%
  mutate_if(is.character, as.factor) %>%
  select(Attrition, everything())
# attach so we don't have to keep writing DDSA$
attach(DDSA)
```


```{r}
# View observations and variables
glimpse(DDSA)
```

```{r}
# View summary statistics
summary(DDSA)
```

  
```{r}
# Changed the following variables to categorical to eventually have a LifeSatisfaction variable
DDSA$DistanceFromHome <- cut(DDSA$DistanceFromHome, breaks = c(-Inf, 9, 21, Inf), labels=c("Poor", "Fair", "Good"))

DDSA$RelationshipSatisfaction <- cut(DDSA$RelationshipSatisfaction, breaks = c(-Inf, 2, 3, Inf), labels=c("Poor", "Fair", "Good"))

DDSA$WorkLifeBalance <- cut(DDSA$WorkLifeBalance, breaks = c(-Inf, 2, 3, Inf), labels=c("Poor", "Fair", "Good"))

```


```{r}
ggplot(data = DDSA) +
  geom_bar(mapping = aes(x=DistanceFromHome))
```


```{r}
ggplot(data = DDSA) +
  geom_bar(mapping = aes(x=RelationshipSatisfaction))
```

```{r}
ggplot(data = DDSA) +
  geom_bar(mapping = aes(x=WorkLifeBalance))
```



```{r}
# Is there a relationship between Age and Income. 
# Color each point based on the Gender of the participant
ggplot(data=DDSA) +
  geom_point(mapping = aes(x = Age, y = MonthlyIncome, color=Gender)) +
  geom_smooth(mapping = aes(x = Age, y = MonthlyIncome))
```


```{r}
# Split test/training sets ~ uses the rsample package
set.seed(100)
train_test_split <- initial_split(DDSA, prop = 0.8)
train_test_split
```

```{r}
# Retrieve train and test sets
train_tbl <- training(train_test_split)
test_tbl <- testing(train_test_split)
```

```{r}
table(test_tbl$Attrition)
```


```{r}
237/nrow(test_tbl)
```

```{r}
modelCart = rpart(Attrition ~ ., data=train_tbl, method="class")
#Plot the model
prp(modelCart)
```

```{r}
#Predict the test data
predictionCart <- predict(modelCart, newdata=test_tbl, type="class")

#CART Accuracy
#Confusion matrix 
t1 <- table(test_tbl$Attrition, predictionCart)


#CART model accuracy
(t1[1]+t1[4])/(nrow(test_tbl))
```

```{r}

modelRf = randomForest(Attrition ~ ., data=train_tbl, ntree = 100, mtry = 5, importance = TRUE, method="class")
print(modelRf)
```

```{r}
#OOB vs No. Of Trees
# Out-of-bag (OOB) error ~ a method of measuring the prediction error of random forests, 
# boosted decision trees, and other machine learning models utilizing bootstrap aggregating 
#(bagging) to sub-sample data samples used for training.
plot(modelRf, main="")
legend("topright", c("OOB", "0", "1"), text.col=1:6, lty=1:3, col=1:3)
title(main="Error Rates Random Forest")
```


```{r}
## List the importance of the variables.
impVar <- round(randomForest::importance(modelRf), 2)
impVar[order(impVar[,3], decreasing=TRUE),]
```

```{r}
# Most important variables of attrition
attrition_variables <- DDSA %>%
  tibble::as_tibble() %>%
  select(Attrition, OverTime,Age, MonthlyIncome) %>%
  rowid_to_column(var = "Case")
attrition_variables
```


